\section{Results and Discussion}

\subsection{Data Collection and Analysis}

Qualitative data collection for this study was done using end of the
semester surveys. Course surveys are delivered by the University
Office of Institutional Effectiveness. The instructor of the course
only receives results of the survey. Eight questions in the survey are
restricted to a 1-5 Likert scale while four questions are open ended
text responses\cite{likert}. The surveys are sent to every student
taking the course via email. The surveys are optional and as such not
all students completed the survey. The data for the course was
compiled for all questions and compared against the Departmental
average. This provides a base of comparison for this course across the
Department of Mechanical Engineering. It is worth noting that the
authors do reflect on how their own positionality may affect
interpretation of data. This reflectivity is a core characteristic in
qualitative research and is important in establishing credibility and
showing transparency. A more in depth analysis of the results are
examined in the discussion section.  

\subsection{Results}

The main goal of implementing this survey was to determine the answer
to the following question: {\bf What response does implementation of
  the kit yield from students?} To answer this question, the 4th
question in the course survey will be examined. This question states:
{\it "What did you like best about how the instructor taught the
  course?"} Table \ref{tab:quotes} includes examples of questionnaire
responses which is in the appendix.

\begin{table}[H]
    \centering
    \begin{tabular}{c|p{11cm}}
        Semester &  Quotes \\
        \hline 
        \hline
        Fall 2019 & "The course was taught expertly with proper use of in class equipment available and hands on design problems with experiments relative to the material being taught." \\
         & "I like how he introduced us to the Circuit Playground which allowed to be hands-on since none of my other classes are." \\
        \hline
        Spring 2020 (Remote Mid-Way) & "Hands on experience" \\
        & "I especially enjoyed the hands-on Fridays portion of the course. The practical knowledge of creating something with the book-learning we gained during the lecture was priceless."\\
        & "Fridays were my favorite days. I got to experience hands on projects where I learned the most from." \\
        \hline
        Fall 2020 (Hybrid) & "I loved the hands on approach to the course. It is the first course, outside senior design, where we had the opportunity to exercise our engineering knowledge on an actual project."\\
        & "The projects! this [taught] a lot of people hands-on skills" \\
        \hline
        Spring 2021 (Hybrid) & "I liked the hands on aspect of the class the most"\\
        & "I wish all other class were taught as well"\\
        & "I like that we actually had a hands on project, and several projects that were fun to do" \\
        \hline
        Fall 2021 & "I love how he tries to engage his students and help them learn real world engineering, not just textbook stuff. He really wants to watch his students succeed inside and outside of the classroom. We need more classes and professors like this in engineering! It was a fantastic class and instructor" \\
        \hline 
        Spring 2022 & "I had no interest in coding or robotics like things but now I do. I grew an interest in coding after absolutely hating it. I love seeing the application of what I've learned so far in my degree path. I am a hands-on learner, so the labs and the project were my favorite."\\
        \hline
        Fall 2022 & "The hands on projects and labs" \\ 
        & "Very engaging with the students and cared for each student and wanted to help when needed. Gave good real world applications as well as fun, interesting assignments that helped us students learn."
    \end{tabular}
    \caption{Questionnaire responses to "What did you like best about how the instructor taught the course?"}
    \label{tab:quotes}
\end{table}

Note that certain semesters were during the Pandemic of COVID-19. In
the Spring of 2020 the University transitioned to fully online
lectures on March 23rd. That was mid-way through the semester. In Fall
2020 and Spring 2021 the students participated in a hybrid lecture
format where students were both allowed to come to class as well as
remain remote and log on via Zoom. In the Fall 2021 semester, the
University returned to fully in person lectures without masks.   

To further answer this question, results from the
question ``How effective was the instructor in helping students
achieve course objectives" is shown in Table \ref{tab:scores} also in
the appendix. This table shows the response rate per semester as well
as average score for the question  The last column shows the average
score across the department. Spring 2020 has an asterisk because the
University of South Alabama created a different course survey due to
the onset of COVID-19. Instead the question ``Please tell us your
perception of the quality of the class prior to the transition to
[online] on March 23rd" was used during Spring 2020. As such, the
departmental scores are not listed.

\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c}
        Semester &  Response Rate & Average Score (1-5) & Department Avg Score (1-5) \\
        \hline 
        \hline
        Fall 2019 & 22\% & 4.20 & 3.63 \\
        \hline
        Spring 2020 (Remote Mid-Way) $^*$ & 30\% & 4.66$^*$ & N/A \\
        \hline
        Fall 2020 (Hybrid) & 46\% & 4.64 & 3.57 \\
        \hline
        Spring 2021 (Hybrid) & 45\% & 4.75 & 3.73 \\
        \hline
        Fall 2021 & 42\% & 4.70 & 4.14 \\
        \hline
        Spring 2022 & 47\% & 4.94 & 3.91 \\
        \hline
        Fall 2022 & 57\% & 5.0 & 4.0 \\
        \hline
        Average & 41.3\% & 4.70 & 3.83 \\
    \end{tabular}
    \caption{Average Score for "Instructor Effectiveness in Helping Students Achieve Course Objectives" (*Alternate question during COVID-19 Pandemic)}
    \label{tab:scores}
\end{table}

From analysis of the surveys, 4 themes emerged which capture student
perceptions of the newly developed course. These include: Teaching
Style, Course Design \& Comparison, Balance between Theory \&
Application and Connected Learning. Table \ref{t:themes} shows these
four themes with definitions of each. These themes overall represent
the perspectives students had on the course based on the survey
results. 

\begin{table}[H]
\centering
\begin{tabular}{|c|p{9cm}|}
\hline
{\bf Theme} & {\bf Definition} \\
\hline
\hline
Teaching Style & Instructor teaching style and personality has an impact on course which is sometimes hard to distinguish from the course design itself \\
\hline
Course Design \& Comparison & Student evaluation of different aspects of the course, including the flipped-classroom design, structure of lecture and class time, as well as specifics of the book. Course is compared to others.\\
\hline
Balance between Theory \& Application & Students enjoyed the application aspect of the PBL Instrumentation course, but suggested adding more theory to the GitBook provided for the course. Students wanted more harmony between the textbook and the kit. \\
\hline
Connected Learning & Students extend learning outside of the classroom and make connections to their personal life \\
\hline
\end{tabular}
\caption{Resultant themes and definitions of themes
Theme}\label{t:themes}
\end{table}

\subsection{Discussion}

This lab at home kit has been implemented since the Fall of 2019. By
the time of this writing, the kit has been implemented for 7
semesters, three of which were during COVID-19. The kit was very
useful during the COVID-19 pandemic (Spring 2020, Fall 2020 and Spring
2021) because students could order the kit and complete the projects
remotely. If students had trouble they could email issues or take a
video and share it or even set up a quick video conferencing call. The
students were able to see their course objectives hands on which
provided a unique way of learning during the pandemic. When the
students used the kit in the classroom once the University returned to
in person lectures, the students still enjoyed the projects as shown
in the survey results. 

In regards to the second research question about student satisfaction
of the course through the use of the kit, Table \ref{tab:quotes}
clearly show a positive response in regards to the projects and the
lab at home kit. For brevity only two to three quotes were shown but
for some semesters at least 25 quotes were generated with many of them
reflecting on the "hands on learning" component of the course. 

Furthermore, Table \ref{tab:scores} shows an on average course rating
that is 22\% higher than the departmental average. It can be said with
confidence that the quotes in Table \ref{tab:quotes} are in direct
response to the implementation of the kit and that the students would
not have written these words had the kit not been an addition to the
course. This proves the first research question that a kit can be
implemented as well as answers the second research question. 

When these quotes are taken into consideration with the higher course
ratings and higher student responses, it is evident that the take-home
lab kit promoted more active student engagement in the course and, by
extension, more active student learning. This data shows, in
conjunction with student commentary, that the projects associated with
kits fostered a positive learning experience for students while also
covering required content for the course. Projects like this one are a
strong strategy professors can add to their repertoire as they teach
content. Per Gardner's and Bloom's theories of learning, this would
indicate the students likely mastered content and skills in this
setting just as well as, if not better than they would in a more
traditional lecture format\cite{Armstrong,Gardner}. 

\subsection{Limitations of Findings}

Although survey analysis resulted in themes that gave perspectives on
the course, there are clear limitations in the resultant findings. The
authors are well aware that this data does not conclusively show that
implementing a kit in a course increases achievement of course
objectives. Many other variable are present in this study, such as the
instructor, the course and even the classroom the course is taught
in. This study is limited in generalizability based on the small
response rate in some of the semesters. Findings are also not
generalizable to all engineering Instrumentation courses across the
world or even the United States given the influence of the
instructor's teaching style and personality in the course. Future
research should expand on the study by recruiting individual interview
participants and survey respondents to gain a better understanding of
the impact of the course on students.  

However, findings are useful for instructors seeking to improve their
own course by adopting the at-home kit and documentation
developed. This theme appeared multiple times among students and it is
very possible that students were confused about whether they liked the
course or liking the professor. For students, the instructor had a big
influence on making the course enjoyable; Preliminary results from
this qualitative study can be used to inform course design and
teaching practice in future courses. 

\section{Conclusions}
A lab at home kit has been described here. This kit is part of the
curriculum for Instrumentation \& Experimental Methods and uses the
CircuitPlayground Express (CPX) from Adafruit as well as other
electronic components. The CPX uses CircuitPython, a derivative of
Python. Python like all scripting languages allows students to focus
on writing concise code to use the CPX as a tool rather than getting
bogged down in syntax, compilation and runtime errors. All software is
free, open source and has numerous examples on the Adafruit Learn page
as well as the internet at large and Github \cite{Github}. 

As with all other courses in engineering it is possible to teach this
course without any hands on material. Instead, a project based
learning (PBL) style is utilized where students use the CPX and other
components of the lab at home kit to complete guided projects
requiring data acquisition, analysis and post-processing all geared
towards enhancing learning of course objectives. The final project in
the class allows the students to be creative, take ownership,
collaborate with others, and use critical thinking to develop
something new.  

The responses from the students is positive with a 22\% increase over
the department average over 7 semesters. The qualitative survey
responses from students are also positive and show that the kit is
effective in enhancing student satisfaction through interaction of
tangible objects. Student satisfaction correlates to student
performance as shown in the literature. Hopefully, similar kits can be
created for other classes at USA as well as other universities in STEM
across the world.  
